{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\Abhishek's\n",
      "[nltk_data]     PC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to C:\\Users\\Abhishek's\n",
      "[nltk_data]     PC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#downloading libraries\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import re\n",
    "import numpy as np\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from string import punctuation\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "import pickle\n",
    "\n",
    "#nltk.download()\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Dense, Dropout, Flatten  \n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "import keras\n",
    "from keras.layers import Dense, Conv2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import MaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.layers import Activation\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers import Dropout\n",
    "from keras.models import Sequential\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn import model_selection\n",
    "from sklearn.ensemble import AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import praw\n",
    "import pprint\n",
    "import pandas as pd\n",
    "reddit = praw.Reddit(client_id='300HIOocldVcKA', client_secret='PCktLUhpPaRB1RrBCouEDPdpEBU', user_agent='abhishek chopra')\n",
    "posts = []\n",
    "india_subreddit = reddit.subreddit('India')\n",
    "posts=[]\n",
    "for post in india_subreddit.top('all',limit=1000):\n",
    "    posts.append([post.title, post.score, post.id, post.url, post.num_comments, post.selftext, post.created,post.link_flair_text])\n",
    "posts_pd = pd.DataFrame(posts,columns=['title', 'score', 'id', 'url', 'num_comments', 'body', 'created','flair'])\n",
    "\n",
    "for post in india_subreddit.top('week',limit=1000):\n",
    "    if post.title not in posts_pd['title'].unique():\n",
    "         posts.append([post.title, post.score, post.id, post.url, post.num_comments, post.selftext, post.created,post.link_flair_text])\n",
    "posts_pd = pd.DataFrame(posts,columns=['title', 'score', 'id', 'url', 'num_comments', 'body', 'created','flair'])\n",
    "\n",
    "for post in india_subreddit.hot(limit=1000):\n",
    "    if post.title not in posts_pd['title'].unique():\n",
    "         posts.append([post.title, post.score, post.id, post.url, post.num_comments, post.selftext, post.created,post.link_flair_text])\n",
    "posts_pd = pd.DataFrame(posts,columns=['title', 'score', 'id', 'url', 'num_comments', 'body', 'created','flair'])\n",
    "\n",
    "for post in india_subreddit.new(limit=1000):\n",
    "    if post.title not in posts_pd['title'].unique():\n",
    "         posts.append([post.title, post.score, post.id, post.url, post.num_comments, post.selftext, post.created,post.link_flair_text])\n",
    "posts_pd = pd.DataFrame(posts,columns=['title', 'score', 'id', 'url', 'num_comments', 'body', 'created','flair'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "for flair in posts_pd['flair']:\n",
    "    if flair == 'Unverified' or flair == 'AMA' or flair == 'AMA Concluded':\n",
    "        posts_pd['flair'][i]='AMA'\n",
    "        print(posts_pd['flair'][i])\n",
    "    i=i+1\n",
    "i=0\n",
    "for flair in posts_pd['flair']:\n",
    "    if flair == 'Policy & Economy' or flair == 'Policy' or flair == 'Demonetization' or flair == 'Policy/Economy ':\n",
    "        posts_pd['flair'][i]='Policy/Economy'\n",
    "        print(posts_pd['flair'][i])\n",
    "    i=i+1   \n",
    "i=0\n",
    "for flair in posts_pd['flair']:\n",
    "    if flair == 'Entertainment' or flair == 'Misleading' or flair == 'r/all' or flair == '/r/all':\n",
    "        posts_pd['flair'][i]='Non-Political'\n",
    "        print(posts_pd['flair'][i])\n",
    "    i=i+1    \n",
    "i=0\n",
    "for flair in posts_pd['flair']:\n",
    "    if flair == 'Science & Technology':\n",
    "        posts_pd['flair'][i]='Science/Technology'\n",
    "        print(posts_pd['flair'][i])\n",
    "    i=i+1    \n",
    "    \n",
    "flair_list=['AMA','AskIndia','Business/Finance','Food','Non-Political','Photography','Policy/Economy','Politics','Science/Technology','Sports','[R]eddiquette']\n",
    "i=0\n",
    "for flair in posts_pd['flair']:\n",
    "    if flair not in flair_list:\n",
    "        posts_pd['flair'][i]='waste'\n",
    "        print(posts_pd['flair'][i])\n",
    "    i=i+1  \n",
    "\n",
    "temp=[]\n",
    "for i in range(len(posts_pd)):\n",
    "    if posts_pd['flair'][i]!='waste':\n",
    "        temp.append([posts_pd.title[i], posts_pd.score[i], posts_pd.id[i], posts_pd.url[i], posts_pd.num_comments[i], posts_pd.body[i], posts_pd.created[i],posts_pd.flair[i]])\n",
    "posts_corr= pd.DataFrame(temp,columns=['title', 'score', 'id', 'url', 'num_comments', 'body', 'created','flair'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit = reddit = praw.Reddit(client_id='300HIOocldVcKA', client_secret='PCktLUhpPaRB1RrBCouEDPdpEBU', user_agent='abhishek chopra')\n",
    "\n",
    "subreddit = reddit.subreddit('india')\n",
    "topics_dict = {\"flair\":[], \"title\":[], \"score\":[], \"id\":[], \"url\":[], \"body\":[],\"comms_num\": [], \"created\": [], \"comments\":[]}\n",
    "import datetime as dt\n",
    "def date_convertor(data):\n",
    "    return dt.datetime.fromtimestamp(data)\n",
    "\n",
    "for flair in flair_list:\n",
    "  \n",
    "  get_subreddits = subreddit.search(flair, limit=100)\n",
    "  \n",
    "  for submission in get_subreddits:\n",
    "    \n",
    "    topics_dict[\"flair\"].append(flair)\n",
    "    topics_dict[\"title\"].append(submission.title)\n",
    "    topics_dict[\"score\"].append(submission.score)\n",
    "    topics_dict[\"id\"].append(submission.id)\n",
    "    topics_dict[\"url\"].append(submission.url)\n",
    "    topics_dict[\"body\"].append(submission.selftext)\n",
    "    topics_dict[\"comms_num\"].append(submission.num_comments)\n",
    "    topics_dict[\"created\"].append(submission.created)\n",
    "    \n",
    "    submission.comments.replace_more(limit=None)\n",
    "    comment = ''\n",
    "    for top_level_comment in submission.comments:\n",
    "        comment = comment + ' ' + top_level_comment.body\n",
    "    topics_dict[\"comments\"].append(comment)\n",
    "    \n",
    "topics_data = pd.DataFrame(topics_dict)\n",
    "_timestamp = topics_data[\"created\"].apply(date_convertor)\n",
    "topics_data = topics_data.assign(timestamp = _timestamp)\n",
    "del topics_data['created']\n",
    "topics_data.to_csv('reddit-india-data.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
